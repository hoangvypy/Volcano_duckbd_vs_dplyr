{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKIceZsbXs34cM74spW+pJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangvypy/Volcano_duckbd_vs_dplyr/blob/main/gen_parquet_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnyaf-UInq91"
      },
      "outputs": [],
      "source": [
        "# gen_parquet_files.py\n",
        "# -------------------------\n",
        "# Data generation adapted from Zach Wilson's his newsletter email,\n",
        "# \"DuckDB benchmarked against Spark\"\n",
        "\n",
        "# For very large data generation 27e7 and 5e8 (11GB and 22GB respectively),\n",
        "# my local 8 GB RAM laptop ran out of memory during processing.\n",
        "# My 8 GB RAM personal laptop couldn't handle,\n",
        "# so I moved to Collab for higher free RAM processing\n",
        "\n",
        "import duckdb\n",
        "import os\n",
        "\n",
        "# Get the folder\n",
        "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))          #for local folder\n",
        "BASE_DIR = os.getcwd()                                           #for colab\n",
        "\n",
        "# Create dummy_data folder inside project if it doesn't exist\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"dummy_data\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def gen_dataset(rows):\n",
        "    lower = \"2020-01-01\"\n",
        "    upper = \"2025-01-01\"\n",
        "    con = duckdb.connect()\n",
        "\n",
        "    file_path = os.path.join(OUTPUT_DIR, f\"ds_{rows}_rows.parquet\")\n",
        "\n",
        "    con.execute(f\"\"\"\n",
        "        COPY (\n",
        "          SELECT\n",
        "            t.row_id,\n",
        "            CAST(uuid() AS VARCHAR) AS txn_key,\n",
        "            DATE '{lower}'\n",
        "              + (random() * (date_diff('day', DATE '{lower}', DATE '{upper}')))::INT AS rand_dt,\n",
        "            ROUND(random() * 100, 2) AS rand_val,\n",
        "            SUBSTR('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
        "                   1 + (random() * 25)::INT, 1) AS rand_str\n",
        "          FROM generate_series(1, {rows}) t(row_id)\n",
        "        ) TO '{file_path}' (FORMAT 'parquet');\n",
        "    \"\"\")\n",
        "\n",
        "#sizes = [500, 5000]\n",
        "#sizes = [50000, 500000, 5000000, 50000000]\n",
        "sizes = [270000000, 500000000]\n",
        "for n in sizes:\n",
        "    print(f\"Generating {n} rows...\")\n",
        "    gen_dataset(n)\n",
        "\n",
        "print(\"âœ… All datasets generated!\")"
      ]
    }
  ]
}